{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(os.path.join(\"Resources\", \"Data\", \"growth_designation.csv\"))\n",
    "# raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = raw_data['GrowthOutcome']\n",
    "target_names = ['Growth', 'No-Growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 12) (895,)\n"
     ]
    }
   ],
   "source": [
    "X = raw_data.drop(columns=['GrowthOutcome'])\n",
    "y = raw_data[\"GrowthOutcome\"]\n",
    "feature_names = X.columns\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044642857142857"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=800)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1149461156140583, 'ProductionValue'),\n",
       " (0.10571708939374842, 'TotalProduction'),\n",
       " (0.10355266695243368, 'Imidacloprid'),\n",
       " (0.10321059865971068, 'PricePerLB'),\n",
       " (0.1024884553938062, 'Stocks'),\n",
       " (0.10028041392245982, 'CombinedNeonic'),\n",
       " (0.09372191711015326, 'YieldPerColony'),\n",
       " (0.08727195354152362, 'ColonyCount'),\n",
       " (0.0683597781051893, 'Thiamethoxam'),\n",
       " (0.050306533737189324, 'Clothianidin'),\n",
       " (0.049328940295159635, 'Acetamiprid'),\n",
       " (0.02081553727456775, 'Thiacloprid')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\Users\\Lauren\\anaconda3\\lib\\site-packages\\sklearn\\experimental\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-608429861898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_halving_search_cv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHalvingGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enable_halving_search_cv' from 'sklearn.experimental' (C:\\Users\\Lauren\\anaconda3\\lib\\site-packages\\sklearn\\experimental\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create Grid Search\n",
    "\n",
    "param_grid = {'max_depth': [3, 5, 10],\n",
    "              'min_samples_split': [2, 5, 10]}\n",
    "base_estimator = RandomForestClassifier(random_state=0)\n",
    "X, y = make_classification(n_samples=1000, random_state=0)\n",
    "sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
    "                         factor=2, resource='n_estimators',\n",
    "                        max_resources=30).fit(X, y)\n",
    "sh.best_estimator_\n",
    "RandomForestClassifier(max_depth=5, n_estimators=800, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RandomForest Classifier\n",
    "\n",
    "kepler_186f_RFClassifier = RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)\n",
    "# Fit the RandomForestClassifier to train data\n",
    "kepler_186f_RFClassifier = kepler_186f_RFClassifier.fit(X2_train, y2_train)\n",
    "# Score the RandomForestClassifier with test data\n",
    "print(kepler_186f_RFClassifier.score(X2_test, y2_test))\n",
    "feature_importance2 = sorted(zip(kepler_186f_RFClassifier.feature_importances_, feature_names), reverse=True)\n",
    "feature_importance2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Create CSV files of the feature importances from both random forest models to be used in the tableau visuals</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Random Forest Classifier\n",
    "rf1_features = {}\n",
    "for importance, feature in feature_importance:\n",
    "    rf1_features[feature] = importance\n",
    "rf1_importance_df = pd.DataFrame.from_dict(rf1_features, orient='index')\n",
    "\n",
    "\n",
    "# Random Forest Classifier with Grid Search\n",
    "rf2_features = {}\n",
    "for importance, feature in feature_importance2:\n",
    "    rf2_features[feature] = importance\n",
    "rf2_importance_df = pd.DataFrame.from_dict(rf2_features, orient='index')\n",
    "\n",
    "# rf1_importance_df\n",
    "rf2_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_features = rf1_importance_df.merge(rf2_importance_df,left_index=True, right_index=True).reset_index()\n",
    "joined_features = joined_features.rename(columns={\"index\":\"Feature\", \"0_x\":\"RF\", \"0_y\":\"RF & GS\"})\n",
    "joined_features.to_csv(\"Resources/Data/rf_feature_importance.csv\", index=False)\n",
    "joined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "honeybee_prediction = rf.predict(X_test)\n",
    "print(classification_report(y_test, honeybee_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
